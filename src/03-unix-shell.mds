% Introduction to Bioinformatics
% Lesson 3 - Unix Scripting & Automation


# First some housekeeping:

* Questions from last week?
* Try alnvu again: `av -L 99999 -w 99999 -c output/alignment.fasta | less -S`
* Tmux bindings?: Replace `#{pane_current_path}` with `$PWD` in `nano ~/.tmux.conf`


# Shell scripting

_In which our flying, speaking beasts assemble and become legion_


# The Unix shell is more than just a shell

It's also a mini-programming language!

Building new commands out of old commands is part of Unix composability


# For bioinformatics this means

* Simple analysis tools/commands
* Automation


# Shell scripting is just "duct tape"

* Perfect for connecting existing shell commands together
* Less so for more complicated data flow and logic (for which we have python, R, etc.)


# Our first script!

We're going to create a `build.sh` script to automate our analyses.


# A shell script is just a list of commands to be executed

Run `nano build.sh`, then add:

```
ls -l | column -t
echo "IT WORKED!"
```

* Save (`Ctrl-o`)
* Switch to a new t-mux pane (`Ctrl-a |`)
* Run `bash build.sh` from within the `bioinfclass` directory


# Error handling

Back in our `nano build.sh` pane, edit to look like:

```
# Sane error handling settings
set -euf -o pipefail

ls -l | column -t
# Put in a "bug":
asdfasdfasdf

echo "IT WORKED!"
```

Save and rerun `bash build.sh`.
Remove the "bug" and rerun again.

Note: Lines starting with `# ` are comments and not executed.


# Making into a proper command

Edit your `nano build.sh` to look like:

```
#!/bin/bash

# Sane error handling settings
set -euf -o pipefail

ls -l | column -t
echo "IT WORKED!"
```

The `#!` is a "shebang": a special comment line that tells computer how to run our script


# Now make the script executable!

At the terminal:

```
chmod +x build.sh

# Note "x" when we use `ls -l`
ls -l build.sh

file build.sh

# Now it's a command/program!
./build.sh
```


# Taking a step back to optimize our environment with dotfiles

We've already seen dotfiles in use with Tmux.
Many other Unix programs accept configuration from dotfiles, including `nano` and our Unix shell itself.


# First some things to make nano nicer

Run `nano ~/.nanorc`, then enter:

```
set tabsize 4
set tabstospaces
set autoindent
```

It's not perfect, but it's a start.


# Now our environment

Tired of running `module load intro-bio`?
Or editing your `PATH` variable?

Run `nano ~/.bashrc`:

```
module load intro-bio
export PATH=~/bin/:$PATH
```

Now run `source ~/.bashrc` to reload.


# Back to biology


# Counting sequences per species

In our `build.sh` file, replace the `column -t` command with:

```
# Compute number of sequences per species
csvuniq -zc species data/sfv.csv > output/seqs_per_species.csv
```

Type `Ctrl-o` to save without exiting.


# Run and investigate

In the shell:

```
ls output

./build.sh

ls output

csvlook output/seqs_per_species.csv
```


# Add some other steps

In `nano build.sh` file, add to the end:

```
# Compute number of sequences per specimen
csvuniq -zc specimen,species,location data/sfv.csv > output/seqs_per_specimen.csv

# Use those results to count specimens per species
csvuniq -zc species output/seqs_per_specimen.csv > output/specs_per_species.csv

# Also use them to count specimens by species and location
csvuniq -zc species,location output/seqs_per_specimen.csv > output/specs_per_species_location.csv
```


# Run and investigate

In the shell:

```
./build.sh

csvlook output/seqs_per_specimen.csv | less -S
```


# How shell variables work

To clarify and simplify, we introduce _variables_!

In the shell:

```
# Assign the value "output" to the variable outdir
# Note no spaces around the "="
outdir="output"

# We can use that variable in further commands by prepending $
echo $outdir
ls $outdir
```


# Cleaning things up with variables

In our `build.sh` file:

```
# Specify output directory, and name input data
outdir="output"
metadata="data/sfv.csv"


# Compute number of sequences per species
seqs_per_species="$outdir/seqs_per_species.csv"
csvuniq -zc species $metadata > $seqs_per_species

# Compute number of sequences per specimen
seqs_per_specimen="$outdir/seqs_per_specimen.csv"
csvuniq -zc specimen,species,location $metadata > $seqs_per_specimen
```


# Continuing variable clean up

## Using output variables as input:

```
# Use those results to compute number of specimens per species
specs_per_species="$outdir/specs_per_species.csv"
csvuniq -zc species $seqs_per_specimen > $specs_per_species

# Also use them to compute number of specimens per species and location
specs_per_species_location="$outdir/specs_per_species_location.csv"
csvuniq -zc species,location $seqs_per_specimen > $specs_per_species_location
```

<!-- 18 minutes so far -->


# Verify that it runs

```bash
./build.sh

ls output

csvlook output/seqs_per_specimen.csv
```


# Writing your own commands

## The other side of shell scripting, and fulfillment of the dream of composition


# Looking for common command patterns

## Letting laziness lead the way...

We've seen `csvlook ___ | less -S` quite a few times now for looking at csv data.
So let's give this a name!


# Writing a `csvless` script

Open up a new file in `~/bin/csvless`, and write:

```
#!/bin/bash

csvlook $@ | less -S
```

Here `$@` is a "magic" variable that points to all of the arguments passed to the command.


# Testing our `csvless` script

In the shell:

```
chmod +x ~/bin/csvless

csvless data/sfv.csv

csvcut -c sequence,specimen,species data/sfv.csv | csvless
```


# Another quick example: `csvhead`

Open up a new file in `~/bin/csvhead`, and write:

```
#!/bin/bash

csvlook $@ | head -n 20
```

Again, `chmod +x`, then test it!


# Other things to know for shell scripting:

* Iteration and arrays: Let us nest or loop over things like different species or locations and process separately
* Conditionals: Let you run tests to determine what code to run
* find/xargs/parallel: Run a command or program in parallel over a sequence of files

Most of this we'll leave to the book...


# Simple iteration

One line in the terminal:

```
for i in $(ls); do echo "My file $i is cool"; done
```

In a file, you can expand this:

```
for i in $(ls)
do
  echo "My file $i is cool"
done
```


# How we might use this?

We could do a series of computations for partitions of our data.
For instance:

```
# For each location...
locations=($(csvuniq -c location $metadata | tail -n +2))
for location in ${locations[*]}
do
  # Create a location outdir, if it doesn't already exist
  loc_outdir="$outdir/$location"
  mkdir -p $loc_outdir
  
  # Do some computations for $location
done
```


# Conditionals

```
#!/bin/bash

if [commands]
then
  [if-statements]
else
  [else-statements]
fi
```


# Conditional example

```
#!/bin/bash

if grep "pattern" some_file.txt > /dev/null
then
  # commands to run if "pattern" is found
  echo "found 'pattern' in 'some_file.txt"
else
  echo "no such pattern found..."
fi
```

Question: Why do we use `> /dev/null` here?


# find/xargs/parallel

There is lots of explanation in the book, so you can learn more there. But to get a brief sense:

* `find`: Let's you compute very specific lists of files, returned to `stdout` separated by lines
* `xargs`: Can take line separated items, and apply them as arguments to some command
    * Good for large collections
    * Can run in parallel
* `parallel`: More robust version of xargs, with better control over parallelization


# Build tools such as `Scons` and `make` offer the following advantages over shell scripts:

* Only rebuild what's needed (very important with long running programs) by tracking:
    * whether data has changed
    * whether commands have changed
* Generally more robust
* Automatically parallelize (sanely)


# Excercise 1

Add the alignment and tree building we did in the last two sessions to our `build.sh` script.


# Excercise 2

Add the following to the end of our `build.sh` script, and complete the TODO items in comments:

```bash
# For each location...
locations=($(csvuniq -c location $metadata | tail -n +2))
for location in ${locations[*]}
do
  # Create a location outdir, if it doesn't already exist
  loc_outdir="$outdir/$location"
  mkdir -p $loc_outdir

  # Create a subset of the metadata for just that location
  loc_metadata="$loc_outdir/metadata.csv"
  csvgrep -c location -m $location $metadata > $loc_metadata

  # Create a list of sequences sampled from that location
  loc_sequences="$loc_outdir/sequences"
  csvcut -c sequence $loc_metadata > $loc_sequences

  # TODO:
  # * Subset Ex. 1 alignment to sequences from $location using `seqmagick convert`
  # * Build a phylogenetic tree from this alignment subset using FastTree
done
```


# Other exercises

* Write a handy little shell script for doing something (for example, printing the last 20 commands entered)


# Reading

Recommended reading:

* Chapter 12

Reading for next class (if you want to read ahead):

* Chapter 5


# Resources

* SCons (sane `make` alternative) for bioinformatics post - <http://www.metasoarous.com/scons-for-data-science-and-compbio/>
* seqmagick - <http://fhcrc.github.io/seqmagick/> for munging sequence data
* `nano` for simple file editing on the rhinos
* Vim for more powerful text editing - (type `vimtutor` at the terminal...)
* Erick's favorite [video](https://www.youtube.com/watch?v=olH-9b3VJfs) about shell scripting, and [website](http://shellhaters.org/)


# SPOILER ALERT!!!

## The following slides contain solutions to the exercises.

Go no further if you're keen to solve the problems yourself.


# Ex. 1: Automating alignment and tree building

```
#!/bin/bash
# ...

inseqs="data/sfv.fasta"

# Alignment
alignment="$outdir/alignment.fasta"
muscle -maxiters 2 -in $inseqs -out $alignment

# Tree
tree="$outdir/tree.nw"
FastTree -nt $alignment > $tree
```


# Ex. 2: Finish location for loop

```
  # Subset our alignment to just that location
  loc_alignment="$loc_outdir/alignment.fasta"
  seqmagick convert --include-from-file $loc_sequences $alignment $loc_alignment

  # Build a location tree
  loc_tree="$loc_outdir/tree.nw"
  FastTree -nt $loc_alignment
```


# This slide intentionally left almost blank...

[Back to homepage](http://fredhutchio.github.io/intro-bioinformatics)

